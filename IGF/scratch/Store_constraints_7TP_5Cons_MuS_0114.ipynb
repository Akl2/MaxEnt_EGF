{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071723b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c733e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latest constraints that worked with the maximum entropy \n",
    "on_mac = True\n",
    "on_thinkpad = False\n",
    "on_hpg = False\n",
    "\n",
    "if on_mac == True:\n",
    "    data_path = \"/Volumes/hodaakl/\"\n",
    "if on_thinkpad== True:\n",
    "    data_path = \"//exasmb.rc.ufl.edu/blue/pdixit/hodaakl/\"\n",
    "if on_hpg == True:\n",
    "    data_path = \"/blue/pdixit/hodaakl/\"\n",
    "\n",
    "# specify the project you are working on     \n",
    "spec_folder_onServer = data_path + 'A5MCMC_IGF_FoxO/'\n",
    "# path = spec_folder_onServer + '0107_MuS/'\n",
    "# ------------------------------------------\n",
    "\n",
    "# file_name_lambda = path + 'Lambdas.csv'\n",
    "# file_name_error = path+ 'Errors.csv'\n",
    "read_dictionary = np.load(spec_folder_onServer + 'Arrays_for_max_ent/Cons_1213_MuS.npy',allow_pickle='TRUE').item()\n",
    "real_cons = read_dictionary['array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8c8d26",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.73326672e+02, 4.54108606e+02, 4.54927976e+02, 4.36524779e+02,\n",
       "       4.10898456e+02, 3.99717094e+02, 3.96371614e+02, 4.73326672e+02,\n",
       "       4.63365604e+02, 4.48820850e+02, 4.08610485e+02, 3.74722149e+02,\n",
       "       3.59573891e+02, 3.57008177e+02, 4.73326672e+02, 4.40846141e+02,\n",
       "       4.31311828e+02, 3.80035497e+02, 3.30084268e+02, 3.17888074e+02,\n",
       "       3.16343356e+02, 4.73326672e+02, 4.32454721e+02, 3.89352065e+02,\n",
       "       2.73958268e+02, 2.19506117e+02, 2.16909031e+02, 2.21131886e+02,\n",
       "       2.28865070e+05, 2.10509338e+05, 2.11701237e+05, 1.95448774e+05,\n",
       "       1.74203740e+05, 1.65509616e+05, 1.62740579e+05, 2.29008297e+05,\n",
       "       2.19578284e+05, 2.06260524e+05, 1.71882226e+05, 1.46135878e+05,\n",
       "       1.35316891e+05, 1.33540269e+05, 2.28658597e+05, 1.98284244e+05,\n",
       "       1.90315679e+05, 1.49111430e+05, 1.14298312e+05, 1.06619137e+05,\n",
       "       1.05796707e+05, 2.30436021e+05, 1.92391258e+05, 1.56617420e+05,\n",
       "       7.91837397e+04, 5.14056114e+04, 5.02260546e+04, 5.23042157e+04])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b196750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved Sheet2 to dictionary\n",
      "saved 0pM to dictionary\n",
      "saved 10pM to dictionary\n",
      "saved 15pm to dictionary\n",
      "saved 20pM to dictionary\n",
      "saved 25pM to dictionary\n",
      "saved 50pM to dictionary\n",
      "saved 250pM to dictionary\n"
     ]
    }
   ],
   "source": [
    "# load constraints from the data and save all the means and 2nd moments, then save all the required points \n",
    "## saving Data of IGF\n",
    "filepath  = 'Data/IGF/EXP129_RAW.xlsx'\n",
    "xls = pd.ExcelFile(filepath)\n",
    "Data_Dict = defaultdict(lambda: 'Not present')\n",
    "Sheet_labels = ['Sheet2' ,'0pM','10pM','15pm','20pM','25pM', '50pM', '250pM']\n",
    "# conc\n",
    "nSheets = len(Sheet_labels)\n",
    "for i in range(nSheets): \n",
    "    sl = Sheet_labels[i]\n",
    "    df = pd.read_excel(xls, sl ,header=None)\n",
    "    data = df.to_numpy()\n",
    "    Data_Dict[sl] = data\n",
    "    print(f'saved {sl} to dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127e9e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10pM\n",
      "15pm\n",
      "20pM\n",
      "50pM\n",
      "250pM\n",
      "22354.1407661559\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(xls, 'Sheet2' ,header=None)\n",
    "bg_array = df.to_numpy()[:,1]\n",
    "# bg_matrix = np.transpose(np.tile(bg_array, (300,1)))\n",
    "\n",
    "conc_labels = ['10pM','15pm','20pM','50pM', '250pM']\n",
    "# conc\n",
    "bgg = 0 \n",
    "ncc = 0\n",
    "Means_dict = defaultdict(lambda: 'Not present')\n",
    "Var_dict = defaultdict(lambda:'Not present')\n",
    "SecondMoment_dict = defaultdict(lambda:'Not present')\n",
    "for key in conc_labels: \n",
    "    print(key)\n",
    "    matrix = Data_Dict[key][:,1:]\n",
    "    ncells = matrix.shape[1]\n",
    "    bg_matrix = np.transpose(np.tile(bg_array, (ncells,1)))\n",
    "#     print(matrix.shape)\n",
    "    ## subtract \n",
    "    data = matrix - bg_matrix\n",
    "#     if key \n",
    "    bgg += np.sum(data[0,:])\n",
    "    ncc += len(data[0,:]) \n",
    "#     Means_dict[key] = np.mean(data, axis = 1)\n",
    "#     SecondMoment_dict[key] = np.mean(data**2, axis = 1)\n",
    "#     Var_dict[key] = np.var(data, axis = 1)\n",
    "    \n",
    "flour_noligand = bgg/ncc\n",
    "print(flour_noligand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5034a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_foxO = 710*2/3 \n",
    "au_foxO = flour_noligand\n",
    "# scale factor \n",
    "sc = n_foxO/au_foxO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f95ddc",
   "metadata": {},
   "source": [
    "### Removing the background and getting the shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895c489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10pM\n",
      "15pm\n",
      "20pM\n",
      "50pM\n",
      "250pM\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(xls, 'Sheet2' ,header=None)\n",
    "bg_array = df.to_numpy()[:,1]\n",
    "# bg_matrix = np.transpose(np.tile(bg_array, (300,1)))\n",
    "\n",
    "conc_labels = ['10pM','15pm','20pM','50pM', '250pM']\n",
    "# conc\n",
    "bgg = 0 \n",
    "ncc = 0\n",
    "Means_dict = defaultdict(lambda: 'Not present')\n",
    "Var_dict = defaultdict(lambda:'Not present')\n",
    "SecondMoment_dict = defaultdict(lambda:'Not present')\n",
    "for key in conc_labels: \n",
    "    print(key)\n",
    "    matrix = Data_Dict[key][:,1:]\n",
    "    ncells = matrix.shape[1]\n",
    "    bg_matrix = np.transpose(np.tile(bg_array, (ncells,1)))\n",
    "#     print(matrix.shape)\n",
    "    ## subtract \n",
    "    data = (matrix - bg_matrix)*sc\n",
    "#     if key \n",
    "#     bgg += np.sum(data[0,:])\n",
    "#     ncc += len(data[0,:]) \n",
    "    Means_dict[key] = np.mean(data, axis = 1)\n",
    "    SecondMoment_dict[key] = np.mean(data**2, axis = 1)\n",
    "    Var_dict[key] = np.var(data, axis = 1)\n",
    "    \n",
    "# bgg/ncc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baba65be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 61)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_matrix = np.zeros((len(conc_labels), 61))\n",
    "i=0\n",
    "for key in conc_labels:\n",
    "    means_matrix[i,:] = Means_dict[key]\n",
    "    i+=1 \n",
    "np.shape(means_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f9205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shift_dict = defaultdict(lambda: 'not present')\n",
    "data_shift = (np.average(means_matrix[:,0]) - means_matrix[:,0])\n",
    "for i in range(np.shape(means_matrix)[0]):\n",
    "    \n",
    "    means_matrix[i] = means_matrix[i] + data_shift[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe1d78",
   "metadata": {},
   "source": [
    "### Saving the data with bg removal, shift added and scaling .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9871e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10pM\n",
      "(61, 301)\n",
      "15pm\n",
      "(61, 300)\n",
      "20pM\n",
      "(61, 300)\n",
      "50pM\n",
      "(61, 300)\n",
      "250pM\n",
      "(61, 300)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(xls, 'Sheet2' ,header=None)\n",
    "bg_array = df.to_numpy()[:,1]\n",
    "# bg_matrix = np.transpose(np.tile(bg_array, (300,1)))\n",
    "\n",
    "conc_labels = ['10pM','15pm','20pM','50pM', '250pM']\n",
    "# conc\n",
    "bgg = 0 \n",
    "ncc = 0\n",
    "Means_dict = defaultdict(lambda: 'Not present')\n",
    "Var_dict = defaultdict(lambda:'Not present')\n",
    "SecondMoment_dict = defaultdict(lambda:'Not present')\n",
    "i=0\n",
    "for key in conc_labels: \n",
    "    print(key)\n",
    "    matrix = Data_Dict[key][:,1:]\n",
    "    ncells = matrix.shape[1]\n",
    "    bg_matrix = np.transpose(np.tile(bg_array, (ncells,1)))\n",
    "    \n",
    "#     print((matrix - bg_matrix)*sc )\n",
    "    \n",
    "    data = ((matrix - bg_matrix)*sc ) + data_shift[i]\n",
    "    print(data.shape)\n",
    "    Means_dict[key] = np.mean(data, axis = 1)\n",
    "    SecondMoment_dict[key] = np.mean(data**2, axis = 1)\n",
    "    Var_dict[key] = np.var(data, axis = 1)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "# bgg/ncc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd09479",
   "metadata": {},
   "source": [
    "### Getting the contraints and saving them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6058268",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_values = [0,6,12,24,45,60,90]\n",
    "times_constrained = np.array(time_values) #minutes \n",
    "idx_list = np.array(times_constrained/3, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7457fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraints_means_dict = defaultdict(lambda: 'not present')\n",
    "conc_list = [10,15,20,50, 250]\n",
    "conc_labels = ['10pM','15pm','20pM','50pM', '250pM']\n",
    "labels_arr_means = []\n",
    "labels_arr_sm = []\n",
    "cons_arr = np.zeros(len(conc_list)* len(time_values)*2)\n",
    "k=0\n",
    "titles_list = []\n",
    "means_list = []\n",
    "sm_list = []\n",
    "for i in range(len(conc_list)):\n",
    "    for j in range(len(time_values)):\n",
    "        title = f'{conc_list[i]}_pM_{time_values[j]}_min'\n",
    "        # save the means\n",
    "        key = conc_labels[i]\n",
    "        means_list.append(Means_dict[key][idx_list[j]])\n",
    "        # save the second moments \n",
    "        sm_list.append(SecondMoment_dict[key][idx_list[j]])\n",
    "        # save the titles \n",
    "        labels_arr_means.append(f'Means_{title}')\n",
    "        labels_arr_sm.append(f'sm_{title}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d93dc79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[473.32546653 453.95539421 454.78124476 436.23248704 410.40347098\n",
      " 399.13366949 395.76172798 473.32546653 463.28561062 448.62581436\n",
      " 408.09740328 373.94102539 358.67295192 356.08694447 473.32546653\n",
      " 440.58802905 430.97830388 379.29639967 328.95007969 316.65741918\n",
      " 315.10048282 473.32546653 432.13023634 388.68665824 272.3801483\n",
      " 217.49730464 214.8796769  219.13593348 473.32546653 409.38183645\n",
      " 303.53751901 198.119894   191.28937667 189.31085995 187.60775032]\n",
      "[228940.58764282 210438.41850867 211643.06187714 195271.41315022\n",
      " 173882.43174952 165134.64224684 162346.88394029 229086.08937062\n",
      " 219581.51099657 206162.04554114 171541.32103033 145641.90960601\n",
      " 134765.45768148 132979.98907962 228730.83558703 198119.29122717\n",
      " 190096.14953721 148624.60677435 113635.69350336 105926.63288596\n",
      " 105102.80199993 230536.48865845 192196.06455159 156179.47151957\n",
      "  78387.15291841  50578.9350503   49400.25100993  51479.5373443\n",
      " 228628.7673577  171243.4460985   94812.25410163  41139.4503615\n",
      "  38546.65669444  37803.35960649  37188.49923378]\n",
      "['Means_10_pM_0_min', 'Means_10_pM_6_min', 'Means_10_pM_12_min', 'Means_10_pM_24_min', 'Means_10_pM_45_min', 'Means_10_pM_60_min', 'Means_10_pM_90_min', 'Means_15_pM_0_min', 'Means_15_pM_6_min', 'Means_15_pM_12_min', 'Means_15_pM_24_min', 'Means_15_pM_45_min', 'Means_15_pM_60_min', 'Means_15_pM_90_min', 'Means_20_pM_0_min', 'Means_20_pM_6_min', 'Means_20_pM_12_min', 'Means_20_pM_24_min', 'Means_20_pM_45_min', 'Means_20_pM_60_min', 'Means_20_pM_90_min', 'Means_50_pM_0_min', 'Means_50_pM_6_min', 'Means_50_pM_12_min', 'Means_50_pM_24_min', 'Means_50_pM_45_min', 'Means_50_pM_60_min', 'Means_50_pM_90_min', 'Means_250_pM_0_min', 'Means_250_pM_6_min', 'Means_250_pM_12_min', 'Means_250_pM_24_min', 'Means_250_pM_45_min', 'Means_250_pM_60_min', 'Means_250_pM_90_min', 'sm_10_pM_0_min', 'sm_10_pM_6_min', 'sm_10_pM_12_min', 'sm_10_pM_24_min', 'sm_10_pM_45_min', 'sm_10_pM_60_min', 'sm_10_pM_90_min', 'sm_15_pM_0_min', 'sm_15_pM_6_min', 'sm_15_pM_12_min', 'sm_15_pM_24_min', 'sm_15_pM_45_min', 'sm_15_pM_60_min', 'sm_15_pM_90_min', 'sm_20_pM_0_min', 'sm_20_pM_6_min', 'sm_20_pM_12_min', 'sm_20_pM_24_min', 'sm_20_pM_45_min', 'sm_20_pM_60_min', 'sm_20_pM_90_min', 'sm_50_pM_0_min', 'sm_50_pM_6_min', 'sm_50_pM_12_min', 'sm_50_pM_24_min', 'sm_50_pM_45_min', 'sm_50_pM_60_min', 'sm_50_pM_90_min', 'sm_250_pM_0_min', 'sm_250_pM_6_min', 'sm_250_pM_12_min', 'sm_250_pM_24_min', 'sm_250_pM_45_min', 'sm_250_pM_60_min', 'sm_250_pM_90_min']\n",
      "[4.73325467e+02 4.53955394e+02 4.54781245e+02 4.36232487e+02\n",
      " 4.10403471e+02 3.99133669e+02 3.95761728e+02 4.73325467e+02\n",
      " 4.63285611e+02 4.48625814e+02 4.08097403e+02 3.73941025e+02\n",
      " 3.58672952e+02 3.56086944e+02 4.73325467e+02 4.40588029e+02\n",
      " 4.30978304e+02 3.79296400e+02 3.28950080e+02 3.16657419e+02\n",
      " 3.15100483e+02 4.73325467e+02 4.32130236e+02 3.88686658e+02\n",
      " 2.72380148e+02 2.17497305e+02 2.14879677e+02 2.19135933e+02\n",
      " 4.73325467e+02 4.09381836e+02 3.03537519e+02 1.98119894e+02\n",
      " 1.91289377e+02 1.89310860e+02 1.87607750e+02 2.28940588e+05\n",
      " 2.10438419e+05 2.11643062e+05 1.95271413e+05 1.73882432e+05\n",
      " 1.65134642e+05 1.62346884e+05 2.29086089e+05 2.19581511e+05\n",
      " 2.06162046e+05 1.71541321e+05 1.45641910e+05 1.34765458e+05\n",
      " 1.32979989e+05 2.28730836e+05 1.98119291e+05 1.90096150e+05\n",
      " 1.48624607e+05 1.13635694e+05 1.05926633e+05 1.05102802e+05\n",
      " 2.30536489e+05 1.92196065e+05 1.56179472e+05 7.83871529e+04\n",
      " 5.05789351e+04 4.94002510e+04 5.14795373e+04 2.28628767e+05\n",
      " 1.71243446e+05 9.48122541e+04 4.11394504e+04 3.85466567e+04\n",
      " 3.78033596e+04 3.71884992e+04]\n"
     ]
    }
   ],
   "source": [
    "means_arr = np.asarray(means_list)\n",
    "sm_arr = np.asarray(sm_list)\n",
    "\n",
    "## \n",
    "cons_arr = np.concatenate((means_arr, sm_arr), axis = 0 )\n",
    "labels_arr = labels_arr_means + labels_arr_sm\n",
    "### \n",
    "\n",
    "\n",
    "print(means_arr)\n",
    "print(sm_arr)\n",
    "print(labels_arr)\n",
    "print(cons_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44846ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'labels': labels_arr, 'array':cons_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97247d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Volumes/hodaakl/A5MCMC_IGF_FoxO/Arrays_for_max_ent/Cons_0114_35Cond_MuS.npy', dictionary) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45b5d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dict\n",
    "loaded_dict = np.load(spec_folder_onServer + 'Arrays_for_max_ent/Cons_0114_35Cond_MuS.npy',allow_pickle='TRUE').item()\n",
    "cons_arr = loaded_dict['array']\n",
    "l_arr = loaded_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e3207e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cons_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4da28147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Means_10_pM_0_min',\n",
       " 'Means_10_pM_6_min',\n",
       " 'Means_10_pM_12_min',\n",
       " 'Means_10_pM_24_min',\n",
       " 'Means_10_pM_45_min',\n",
       " 'Means_10_pM_60_min',\n",
       " 'Means_10_pM_90_min',\n",
       " 'Means_15_pM_0_min',\n",
       " 'Means_15_pM_6_min',\n",
       " 'Means_15_pM_12_min',\n",
       " 'Means_15_pM_24_min',\n",
       " 'Means_15_pM_45_min',\n",
       " 'Means_15_pM_60_min',\n",
       " 'Means_15_pM_90_min',\n",
       " 'Means_20_pM_0_min',\n",
       " 'Means_20_pM_6_min',\n",
       " 'Means_20_pM_12_min',\n",
       " 'Means_20_pM_24_min',\n",
       " 'Means_20_pM_45_min',\n",
       " 'Means_20_pM_60_min',\n",
       " 'Means_20_pM_90_min',\n",
       " 'Means_50_pM_0_min',\n",
       " 'Means_50_pM_6_min',\n",
       " 'Means_50_pM_12_min',\n",
       " 'Means_50_pM_24_min',\n",
       " 'Means_50_pM_45_min',\n",
       " 'Means_50_pM_60_min',\n",
       " 'Means_50_pM_90_min',\n",
       " 'Means_250_pM_0_min',\n",
       " 'Means_250_pM_6_min',\n",
       " 'Means_250_pM_12_min',\n",
       " 'Means_250_pM_24_min',\n",
       " 'Means_250_pM_45_min',\n",
       " 'Means_250_pM_60_min',\n",
       " 'Means_250_pM_90_min',\n",
       " 'sm_10_pM_0_min',\n",
       " 'sm_10_pM_6_min',\n",
       " 'sm_10_pM_12_min',\n",
       " 'sm_10_pM_24_min',\n",
       " 'sm_10_pM_45_min',\n",
       " 'sm_10_pM_60_min',\n",
       " 'sm_10_pM_90_min',\n",
       " 'sm_15_pM_0_min',\n",
       " 'sm_15_pM_6_min',\n",
       " 'sm_15_pM_12_min',\n",
       " 'sm_15_pM_24_min',\n",
       " 'sm_15_pM_45_min',\n",
       " 'sm_15_pM_60_min',\n",
       " 'sm_15_pM_90_min',\n",
       " 'sm_20_pM_0_min',\n",
       " 'sm_20_pM_6_min',\n",
       " 'sm_20_pM_12_min',\n",
       " 'sm_20_pM_24_min',\n",
       " 'sm_20_pM_45_min',\n",
       " 'sm_20_pM_60_min',\n",
       " 'sm_20_pM_90_min',\n",
       " 'sm_50_pM_0_min',\n",
       " 'sm_50_pM_6_min',\n",
       " 'sm_50_pM_12_min',\n",
       " 'sm_50_pM_24_min',\n",
       " 'sm_50_pM_45_min',\n",
       " 'sm_50_pM_60_min',\n",
       " 'sm_50_pM_90_min',\n",
       " 'sm_250_pM_0_min',\n",
       " 'sm_250_pM_6_min',\n",
       " 'sm_250_pM_12_min',\n",
       " 'sm_250_pM_24_min',\n",
       " 'sm_250_pM_45_min',\n",
       " 'sm_250_pM_60_min',\n",
       " 'sm_250_pM_90_min']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81891f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
